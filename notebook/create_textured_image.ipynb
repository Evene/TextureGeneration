{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create textured image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "#print('backgrounds')\n",
    "data_path = '/unsullied/sharefs/wangjian02/isilon-home/datasets/SURREAL/smpl_data/textures'\n",
    "\n",
    "PRW_img_path = '/unsullied/sharefs/wangjian02/isilon-home/datasets/PRW/frames'\n",
    "CUHK_SYSU_path = '/unsullied/sharefs/wangjian02/isilon-home/datasets/CUHK-SYSU'\n",
    "\n",
    "data_path_list = [PRW_img_path,CUHK_SYSU_path]\n",
    "\n",
    "backgrounds = []\n",
    "\n",
    "for data_path in data_path_list:\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        for name in files:\n",
    "            if name.endswith('.jpg'):\n",
    "                backgrounds.append(os.path.join(root, name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import random\n",
    "from torch.autograd import Function\n",
    "import os\n",
    "import tqdm\n",
    "\n",
    "class DifferentialTextureRenderer(Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, texture_img_flat, render_sparse_matrix):\n",
    "        result = torch.mm(render_sparse_matrix, texture_img_flat)\n",
    "        ctx.save_for_backward(render_sparse_matrix)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        render_sparse_matrix = ctx.saved_tensors[0]\n",
    "        result = torch.mm(render_sparse_matrix.transpose(0, 1), grad_outputs)\n",
    "        return result, None\n",
    "\n",
    "\n",
    "class TextureToImage(nn.Module):\n",
    "\n",
    "    def sparse_mx_to_torch_sparse_tensor(self, sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
    "        indices = torch.from_numpy(np.vstack((sparse_mx.row, sparse_mx.col)))\n",
    "        indices = indices.long()\n",
    "        values = torch.from_numpy(sparse_mx.data)\n",
    "        shape = torch.Size(sparse_mx.shape)\n",
    "        return torch.sparse.FloatTensor(indices, values, shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the input x is uv map batch of (N, C, H, W)\n",
    "        # transfer it into (N, H, W, C)\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        # flat it and transpose it(H * W * C, N)\n",
    "        x_flat = x.reshape(self.batch_size, -1).transpose(0, 1)\n",
    "        if self.isRandom:\n",
    "            action_tensor = random.choice(self.action_sparse_tensor_data)\n",
    "        else:\n",
    "            action_tensor = self.action_sparse_tensor_data[0]\n",
    "        mat = action_tensor['mat']\n",
    "        mask = action_tensor['mask']\n",
    "        bbox = action_tensor['bbox']\n",
    "        mat = nn.Parameter(mat, requires_grad=False)\n",
    "        result_flat = DifferentialTextureRenderer.apply(x_flat, mat)\n",
    "        result_flat = result_flat.transpose(0, 1)\n",
    "        # get the result of (NHWC)\n",
    "        result = result_flat.reshape(self.batch_size, self.img_size, self.img_size, -1)\n",
    "        # to NCHW\n",
    "        result = result.permute(0, 3, 1, 2)\n",
    "        return result, mask, bbox\n",
    "    \n",
    "    \n",
    "    # train,isRandom is True  , test , isRandom is False\n",
    "\n",
    "    def __init__(self, action_npz, batch_size, img_size=224, use_gpu=False, bbox_size=(128, 64),\n",
    "                 center_random_margin=2, isRandom = True):\n",
    "        super(TextureToImage, self).__init__()\n",
    "        #print('start init the texture to image module')\n",
    "        action_npz_data = np.load(action_npz,encoding=\"latin1\")\n",
    "        self.center_random_margin = center_random_margin\n",
    "        self.action_sparse_tensor_data = []\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = img_size\n",
    "        self.bbox_size = bbox_size\n",
    "        self.isRandom = isRandom\n",
    "        \n",
    "        for data in action_npz_data:\n",
    "            data['mat'] = self.sparse_mx_to_torch_sparse_tensor(data['mat'])\n",
    "            data['bbox'] = self.bbox(data['mask'][:, :, 0])\n",
    "            data['mask'] = torch.from_numpy(data['mask']).float() \\\n",
    "                .unsqueeze(0).permute(0, 3, 1, 2).repeat(self.batch_size, 1, 1, 1)\n",
    "\n",
    "            if use_gpu:\n",
    "                data['mat'] = data['mat'].cuda()\n",
    "                data['mask'] = data['mask'].cuda()\n",
    "            self.action_sparse_tensor_data.append(data)\n",
    "        #print('finish init the texture to image module')\n",
    "\n",
    "    def bbox(self, img):\n",
    "        h = self.bbox_size[0]\n",
    "        w = self.bbox_size[1]\n",
    "        rows = np.any(img, axis=0)\n",
    "        cols = np.any(img, axis=1)\n",
    "        cmin, cmax = np.where(rows)[0][[0, -1]]\n",
    "        rmin, rmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "        r_center = float(rmax + rmin) / 2 + random.randint(-self.center_random_margin, 0)\n",
    "        c_center = float(cmax + cmin) / 2 + random.randint(0, self.center_random_margin)\n",
    "\n",
    "        rmin = int(r_center - h / 2)\n",
    "        rmax = int(r_center + h / 2)\n",
    "\n",
    "        cmin = int(c_center - w / 2)\n",
    "        cmax = int(c_center + w / 2)\n",
    "\n",
    "        return (cmin, rmin), (cmax, rmax)\n",
    "\n",
    "    def test(self):\n",
    "        texture_img = cv2.imread('models/default_texture2.jpg')\n",
    "        texture_img = torch.from_numpy(texture_img).unsqueeze(0).float()\n",
    "        texture_img = texture_img.reshape(1, -1).transpose(0, 1)\n",
    "        start_time = time.time()\n",
    "\n",
    "        action_tensor = random.choice(self.action_sparse_tensor_data)['mat']\n",
    "        result_flat = torch.smm(action_tensor, texture_img).to_dense()\n",
    "        result_flat = result_flat.transpose(0, 1)\n",
    "        result_flat = result_flat.reshape(1, 224, 224, 3)\n",
    "        stop_time = time.time()\n",
    "        print('time use: {}'.format(stop_time - start_time))\n",
    "        result_flat = result_flat.numpy()[0, :]\n",
    "        cv2.imshow('result', result_flat.astype(np.uint8))\n",
    "        cv2.waitKey()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding_box_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19732/19732 [1:59:19<00:00,  2.76it/s]\n"
     ]
    }
   ],
   "source": [
    "Sub_Dir = ['bounding_box_train','bounding_box_test','query']\n",
    "Uvmap_Data_Dir = '/unsullied/sharefs/zhongyunshan/isilon-home/datasets/Texture/market-uvmap'\n",
    "output_Data_Dir = '/unsullied/sharefs/zhongyunshan/isilon-home/datasets/Texture/market-textured/'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for sub in Sub_Dir:\n",
    "\n",
    "    print(sub)\n",
    "\n",
    "    uv_map_path = os.path.join(Uvmap_Data_Dir,sub)\n",
    "    out_path = os.path.join(output_Data_Dir,sub)\n",
    "\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path)\n",
    "    for root, dir, names in os.walk(uv_map_path):\n",
    "        for name in tqdm.tqdm(names):\n",
    "            \n",
    "            tex_2_img = TextureToImage(action_npz='/unsullied/sharefs/wangjian02/isilon-home/datasets/texture/tex_gan/walk_64.npy',\n",
    "                               batch_size=1,\n",
    "                               center_random_margin=2,\n",
    "                               isRandom = True)\n",
    "            \n",
    "            \n",
    "            background = cv2.imread(backgrounds[np.random.randint(len(backgrounds), size=1)[0]])\n",
    "            background = cv2.resize(background, (224, 224))\n",
    "            \n",
    "            full_path = os.path.join(root, name)\n",
    "\n",
    "\n",
    "            texture_img = cv2.imread(full_path)\n",
    "            texture_img = cv2.resize(texture_img, (64, 64))\n",
    "            texture_img = torch.from_numpy(texture_img).unsqueeze(0).float()\n",
    "            texture_img = texture_img.permute(0, 3, 1, 2)\n",
    "            texture_img.requires_grad = True\n",
    "            img, mask, bbox = tex_2_img(texture_img)\n",
    "\n",
    "\n",
    "            img = img.squeeze(0).permute(1, 2, 0).detach().numpy().astype(np.uint8)\n",
    "            mask = mask.squeeze(0).permute(1, 2, 0).detach().numpy()\n",
    "            c_center = (bbox[0][0] + bbox[1][0]) / 2\n",
    "            r_center = (bbox[0][1] + bbox[1][1]) / 2\n",
    "\n",
    "            img = img.astype(np.uint8)\n",
    "\n",
    "            img = img * mask + background * (1 - mask)\n",
    "            tl, br = bbox\n",
    "            img = img[tl[1]:br[1], tl[0]:br[0], :]\n",
    "            cv2.imwrite(os.path.join(out_path, name), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
